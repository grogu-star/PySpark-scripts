{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, VectorAssembler\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, ArrayType\n",
    "\n",
    "from numpy import array\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', sep='\\t', header=True)\n",
    "# views = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', sep=',', header=True)\n",
    "\n",
    "train = spark.read.csv('/labs/slaba03/laba03_train.csv', sep=',', header=True)\n",
    "test = spark.read.csv('/labs/slaba03/laba03_test.csv', sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              genres|          genre_list|        genre_vector|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|   Комедии,Мелодрамы|[Комедии, Мелодрамы]|(84,[3,8],[1.0,1.0])|\n",
      "|Ужасы,Триллеры,Др...|[Ужасы, Триллеры,...|(84,[1,2,4,11,13]...|\n",
      "|Ужасы,Комедии,Фан...|[Ужасы, Комедии, ...|(84,[1,3,11,13],[...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@f.pandas_udf(ArrayType(StringType()), f.PandasUDFType.SCALAR)\n",
    "def split(series):\n",
    "    return series.apply(lambda x: x.split(',') if isinstance(x, str) else list())\n",
    "\n",
    "items0 = items.withColumn('genre_list', split(items.genres))\n",
    "\n",
    "count_vectorizer = CountVectorizer(inputCol='genre_list', outputCol='genre_vector')\n",
    "items1 = count_vectorizer.fit(items0).transform(items0).cache()\n",
    "\n",
    "items1.select('genres', 'genre_list', 'genre_vector').where(f.size(f.col('genre_list')) > 1).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+--------------------+--------------------+--------------+-------------+\n",
      "|item_id|user_id|purchase|          genre_pref|       user_response|  genre_vector|item_response|\n",
      "+-------+-------+--------+--------------------+--------------------+--------------+-------------+\n",
      "| 100140| 766847|       0|[0.0,0.0,0.0,0.0,...|0.001920122887864...|(84,[3],[1.0])|          0.0|\n",
      "| 100140| 779642|       0|[0.0,0.3333333333...|0.001166861143523...|(84,[3],[1.0])|          0.0|\n",
      "| 100140| 924533|       0|[0.0,0.4,0.2,0.0,...|0.001933488012374...|(84,[3],[1.0])|          0.0|\n",
      "+-------+-------+--------+--------------------+--------------------+--------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_response = train.groupBy('user_id')\\\n",
    "                .agg(f.sum('purchase').alias('purchase_cnt'), f.count('item_id').alias('item_cnt'))\\\n",
    "                .withColumn('user_response', f.col('purchase_cnt')/f.col('item_cnt')) \\\n",
    "                .select('user_id', 'user_response')\n",
    "\n",
    "user_data = train.where(train.purchase == '1') \\\n",
    "            .join(\n",
    "                items1.select('item_id', 'genre_vector')\n",
    "                .where(items1.content_type == '1'), on='item_id', how='inner'\n",
    "            ) \\\n",
    "            .groupBy('user_id') \\\n",
    "            .agg(Summarizer.mean(items1.genre_vector).alias('genre_pref')) \\\n",
    "            .join(user_response, on='user_id', how='inner')\n",
    "\n",
    "item_response = train.groupBy('item_id') \\\n",
    "                .agg(f.sum('purchase').alias('purchase_cnt'), f.count('item_id').alias('item_cnt')) \\\n",
    "                .withColumn('item_response', f.col('purchase_cnt')/f.col('item_cnt')) \\\n",
    "                .select('item_id', 'item_response')\n",
    "\n",
    "item_data = items1.where(items1.content_type == '1') \\\n",
    "            .join(item_response, on='item_id', how='inner') \\\n",
    "            .select('item_id', 'genre_vector', 'item_response')  \n",
    "\n",
    "data = train.join(user_data, on='user_id', how='inner') \\\n",
    "       .join(item_data, on='item_id', how='inner').cache()\n",
    "\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[0.00192012288786...|\n",
      "|    0|[0.00116686114352...|\n",
      "|    0|[0.00193348801237...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@f.udf(FloatType())\n",
    "def cos_sim(a, b):\n",
    "    a, b = DenseVector(a), DenseVector(b)\n",
    "    n = norm(a, 2) * norm(b, 2)\n",
    "    if n != 0:\n",
    "        return float(a.dot(b)/n)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "@f.pandas_udf(IntegerType(), f.PandasUDFType.SCALAR)\n",
    "def get_label(series):\n",
    "    return series.apply(lambda x: 1 if x == '1' else 0)\n",
    "\n",
    "data = data.withColumn('user_item_sim', cos_sim(data.genre_pref, data.genre_vector))\n",
    "data = data.withColumn('label', get_label(data.purchase))\n",
    "\n",
    "dataset = VectorAssembler(\n",
    "    inputCols=['user_response', 'item_response', 'user_item_sim'],\n",
    "    outputCol='features'\n",
    ").transform(data).select('label', 'features')\n",
    "cached_dataset = dataset.cache()\n",
    "cached_dataset.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GBTClassifier()\n",
    "model = estimator.fit(cached_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сборка тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(test_data.take(1)[0].genre_vector)\n",
    "zero_vec = Sparse_Vector(length, list())\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            features|\n",
      "+-------+-------+--------------------+\n",
      "| 748042| 100140|[0.00153080750095...|\n",
      "| 855465| 100140|[0.00155279503105...|\n",
      "| 878352| 100140|[0.00115517905275...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = test.join(user_data, on='user_id', how='left') \\\n",
    "                .join(item_data, on='item_id', how='left')\n",
    "\n",
    "test_data = test_data.na.fill(value=zero_vec)\n",
    "\n",
    "test_data = test_data.withColumn('user_item_sim', cos_sim(test_data.genre_pref, test_data.genre_vector))\n",
    "test_data = test_data.withColumn('label', get_label(test_data.purchase))\n",
    "\n",
    "test_dataset = VectorAssembler(\n",
    "    inputCols=['user_response', 'item_response', 'user_item_sim'],\n",
    "    outputCol='features'\n",
    ").transform(test_data).select('user_id', 'item_id', 'features')\n",
    "cached_test_dataset = test_dataset.cache()\n",
    "cached_test_dataset.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = model.transform(test_dataset)\n",
    "cached_predict_data = predict_data.cache()\n",
    "cached_predict_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.udf(FloatType())\n",
    "def get_prob(v):\n",
    "    return float(v[1])\n",
    "\n",
    "predict_data_final = predict_data.withColumn('purchase', get_prob(predict_data.probability)) \\\n",
    "                                 .select('user_id', 'item_id', 'purchase') \\\n",
    "                                 .repartition(1) \\\n",
    "                                 .orderBy('user_id', 'item_id')\n",
    "\n",
    "predict_data_final.toPandas().to_csv('/data/home/margarita.cherentsova/lab03_unsorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

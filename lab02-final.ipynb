{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 1 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import FloatType\n",
    "from json import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hdfs hdfs     81.0 K 2022-01-06 18:46 /labs/laba02/autousers.json\r\n",
      "drwxr-xr-x   - hdfs hdfs          0 2022-01-06 18:46 /labs/laba02/logs\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h /labs/laba02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cat: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read JSON file into dataframe\n",
    "df = spark.read.json(\"/labs/slaba02/DO_record_per_line.json\")\n",
    "df.printSchema()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "data1 = data0.where(data0.lang.isin('en', 'es', 'ru')) \\\n",
    "             .drop('cat', 'provider', 'name') \\\n",
    "             .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----+--------------------+--------------------+--------------------+\n",
      "|                desc| id|lang|               words|                  tf|               tfIdf|\n",
      "+--------------------+---+----+--------------------+--------------------+--------------------+\n",
      "|This course intro...|  4|  en|[this, course, in...|(10000,[36,63,138...|(10000,[36,63,138...|\n",
      "|This online cours...|  5|  en|[this, online, co...|(10000,[32,222,36...|(10000,[32,222,36...|\n",
      "|We live in a digi...|  7|  en|[we, live, in, a,...|(10000,[493,572,7...|(10000,[493,572,7...|\n",
      "+--------------------+---+----+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# токенизация\n",
    "regex_tokenizer = RegexTokenizer(inputCol='desc', outputCol='words', pattern=r'[,\\s\\.\\-]')\n",
    "data2 = regex_tokenizer.transform(data1)\n",
    "\n",
    "# расчет tf\n",
    "hashing_tf = HashingTF(inputCol='words', outputCol='tf', numFeatures=10000)\n",
    "data3 = hashing_tf.transform(data2).cache()\n",
    "\n",
    "# обучение модели idf, расчет tf*idf\n",
    "tf_idf_model = IDF(inputCol='tf', outputCol='tfIdf', minDocFreq=2).fit(data3)\n",
    "data4 = tf_idf_model.transform(data3).cache()\n",
    "data4.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_courses(data, course_id):\n",
    "    \"\"\"Функция, которая возвращает 10 наиболее схожих курсов для заданного курса по его id\"\"\"\n",
    "    u = data.where(data.id == course_id).collect()[0].tfIdf\n",
    "    u = DenseVector(u)\n",
    "    u_norm = u.norm(2)\n",
    "\n",
    "    @udf(returnType=FloatType())\n",
    "    def cos_similarity(v):\n",
    "        v = DenseVector(v)\n",
    "        norm = (v.norm(2) * u_norm)\n",
    "        if norm != 0:\n",
    "            return float(v.dot(u)/norm)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    # создание новой колонки, с расчетом косинусной близости\n",
    "    # между векторами tf-idf заданного курса и остальных\n",
    "    _data0 = data.select('id', cos_similarity(data.tfIdf).alias('cosSimilarity'))\n",
    "    _data1 = _data0.repartition(1)\n",
    "\n",
    "    # выборка 10 кусров с наибольшим cosSimilarity\n",
    "    _data2 = _data1.orderBy(col('cosSimilarity').desc()).limit(10)\n",
    "    return {course_id: [row.id for row in _data2.collect()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for lang en, course 21617\n",
      "Calculating for lang en, course 23126\n",
      "Calculating for lang es, course 11556\n",
      "Calculating for lang es, course 16627\n",
      "Calculating for lang ru, course 13702\n",
      "Calculating for lang ru, course 16704\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "target_courses = {\n",
    "    'en': [21617, 23126],\n",
    "    'es': [11556, 16627],\n",
    "    'ru': [13702, 16704],\n",
    "}\n",
    "\n",
    "similar_courses = dict()\n",
    "\n",
    "for lang, course_id_list in target_courses.items():\n",
    "    for course_id in course_id_list:\n",
    "        print(f'Calculating for lang {lang}, course {course_id}')\n",
    "        \n",
    "        data5 = data4.where(data4.lang == lang)\n",
    "        similar_courses.update(get_similar_courses(data5, course_id))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка результата**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "\n",
    "json = dumps(similar_courses, indent=4)\n",
    "\n",
    "print(json)\n",
    "\n",
    "with open('/data/home/margarita.cherentsova/lab02.json', 'w') as f:\n",
    "    f.write(json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
